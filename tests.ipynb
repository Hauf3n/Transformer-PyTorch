{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from flair.data import Sentence\n",
    "from flair.embeddings import WordEmbeddings\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "dtype = torch.float\n",
    "\n",
    "d_model = 300 # embedding size of fasttext models\n",
    "output_lang = 'en' # select language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "torch.Size([16, 8, 12])\n",
      "\n",
      "reshape for linear qvk layer\n",
      "torch.Size([128, 12])\n",
      "\n",
      "apply linear\n",
      "torch.Size([128, 72])\n",
      "\n",
      "reshape to batch_size,seqlen,..\n",
      "torch.Size([16, 8, 72])\n",
      "\n",
      "split into heads and seperate qvk\n",
      "torch.Size([16, 8, 4, 3, 6])\n",
      "\n",
      "permute head to front for parallel processing\n",
      "torch.Size([16, 4, 8, 3, 6])\n",
      "\n",
      "extract q, k, v\n",
      "q torch.Size([16, 4, 8, 6])\n",
      "k torch.Size([16, 4, 8, 6])\n",
      "v torch.Size([16, 4, 8, 6])\n",
      "\n",
      "fuse batch and head dim for parallel processing\n",
      "q torch.Size([64, 8, 6])\n",
      "k torch.Size([64, 8, 6])\n",
      "v torch.Size([64, 8, 6])\n",
      "\n",
      "transpose k\n",
      "k torch.Size([64, 6, 8])\n",
      "\n",
      "multiply q and k + softmax\n",
      "qk torch.Size([64, 8, 8])\n",
      "\n",
      "multiply with v\n",
      "torch.Size([64, 8, 6])\n",
      "\n",
      "reshape to cat heads\n",
      "torch.Size([16, 4, 8, 6])\n",
      "\n",
      "cat all heads\n",
      "torch.Size([16, 8, 24])\n",
      "\n",
      "reshape to multiply with WO\n",
      "torch.Size([128, 24])\n",
      "\n",
      "multiply...\n",
      "torch.Size([128, 12])\n",
      "\n",
      "reshape for next layer\n",
      "torch.Size([16, 8, 12])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "seq_len = 8\n",
    "num_heads = 4\n",
    "e_dim = 6\n",
    "model_size = 12\n",
    "\n",
    "print('input')\n",
    "a = torch.randn(batch_size, seq_len, model_size).to(dtype)\n",
    "print(a.shape)\n",
    "\n",
    "print('\\nreshape for linear qvk layer')\n",
    "b = torch.reshape(a, (batch_size*seq_len,model_size))\n",
    "print(b.shape)\n",
    "print('\\napply linear')\n",
    "b = torch.randn(batch_size*seq_len, num_heads*3*e_dim).to(dtype)\n",
    "print(b.shape)\n",
    "\n",
    "print('\\nreshape to batch_size,seqlen,..')\n",
    "c = torch.reshape(b,(batch_size,seq_len,num_heads*3*e_dim))\n",
    "print(c.shape)\n",
    "\n",
    "print('\\nsplit into heads and seperate qvk')\n",
    "d = torch.reshape(c, (batch_size,seq_len,num_heads,3,e_dim))\n",
    "print(d.shape)\n",
    "\n",
    "print('\\npermute head to front for parallel processing')\n",
    "d = d.permute(0,2,1,3,4)\n",
    "print(d.shape)\n",
    "\n",
    "print('\\nextract q, k, v')\n",
    "q = d[:,:,:,0,:]\n",
    "k = d[:,:,:,1,:]\n",
    "v = d[:,:,:,2,:]\n",
    "print('q',q.shape)\n",
    "print('k',k.shape)\n",
    "print('v',v.shape)\n",
    "\n",
    "print('\\nfuse batch and head dim for parallel processing')\n",
    "q = q.reshape(batch_size*num_heads,seq_len,e_dim)\n",
    "k = k.reshape(batch_size*num_heads,seq_len,e_dim)\n",
    "v = v.reshape(batch_size*num_heads,seq_len,e_dim)\n",
    "print('q',q.shape)\n",
    "print('k',k.shape)\n",
    "print('v',v.shape)\n",
    "\n",
    "print('\\ntranspose k')\n",
    "k = torch.transpose(k, 1, 2)\n",
    "print('k',k.shape)\n",
    "\n",
    "print('\\nmultiply q and k + softmax')\n",
    "qk = torch.bmm(q,k)\n",
    "qk = F.softmax(qk, dim=2)\n",
    "print('qk',qk.shape)\n",
    "\n",
    "print('\\nmultiply with v')\n",
    "qkv = torch.bmm(qk,v)\n",
    "print(qkv.shape)\n",
    "\n",
    "print('\\nreshape to cat heads')\n",
    "qkv = torch.reshape(qkv, (batch_size, num_heads, seq_len, e_dim))\n",
    "print(qkv.shape)\n",
    "\n",
    "print('\\ncat all heads')\n",
    "qkv = qkv.permute(0,2,1,3)\n",
    "qkv  = torch.reshape(qkv, (batch_size, seq_len, num_heads*e_dim))\n",
    "print(qkv.shape)\n",
    "\n",
    "print('\\nreshape to multiply with WO')\n",
    "qkv  = torch.reshape(qkv, (batch_size*seq_len, num_heads*e_dim))\n",
    "print(qkv.shape)\n",
    "\n",
    "print('\\nmultiply...')\n",
    "qkv = torch.randn(batch_size*seq_len, model_size).to(dtype)\n",
    "print(qkv.shape)\n",
    "\n",
    "print('\\nreshape for next layer')\n",
    "qkv = torch.reshape(qkv, ((batch_size, seq_len, model_size)))\n",
    "print(qkv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
